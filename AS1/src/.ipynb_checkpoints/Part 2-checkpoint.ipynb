{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from model import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read each of the multi var datasets\n",
    "sets = []\n",
    "for i in range(1,5):\n",
    "    if i <= 2:\n",
    "        data = pd.read_csv(f\"http://www.cs.iit.edu/~agam/cs584/share/mvar-set{i}.dat\",sep=' ',skiprows=5, names=['x1','x2','y']).reset_index(drop=True)\n",
    "    else:\n",
    "        data = data = pd.read_csv(f\"http://www.cs.iit.edu/~agam/cs584/share/mvar-set{i}.dat\",sep=' ',skiprows=5, names=['x1','x2','x3','x4','x5','y']).reset_index(drop=True)\n",
    "    sets.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing 5-fold cross validation across 4 different polynomial mappings:\n",
      "Dataset 1\n",
      "\tDegree 2:\n",
      "\t\tAverage training MSE: 0.25808761488858145\n",
      "\t\tAverage testing MSE: 0.2597781514068387\n",
      "\tDegree 3:\n",
      "\t\tAverage training MSE: 0.25729910888102253\n",
      "\t\tAverage testing MSE: 0.26088043683043083\n",
      "\tDegree 4:\n",
      "\t\tAverage training MSE: 0.25606766217360927\n",
      "\t\tAverage testing MSE: 0.2603542361948251\n",
      "\tDegree 5:\n",
      "\t\tAverage training MSE: 0.25563148328271373\n",
      "\t\tAverage testing MSE: 0.2617786043747527\n",
      "\tPolynomial of degree 2 gives smallest test error\n",
      "\n",
      "Dataset 2\n",
      "\tDegree 2:\n",
      "\t\tAverage training MSE: 0.019900958935770385\n",
      "\t\tAverage testing MSE: 0.019986308503465566\n",
      "\tDegree 3:\n",
      "\t\tAverage training MSE: 0.01029385848336197\n",
      "\t\tAverage testing MSE: 0.010392009061652323\n",
      "\tDegree 4:\n",
      "\t\tAverage training MSE: 0.010282023257025765\n",
      "\t\tAverage testing MSE: 0.010409804351559427\n",
      "\tDegree 5:\n",
      "\t\tAverage training MSE: 0.00466532923572765\n",
      "\t\tAverage testing MSE: 0.004788226767267469\n",
      "\tPolynomial of degree 5 gives smallest test error\n",
      "\n",
      "Dataset 3\n",
      "\tDegree 2:\n",
      "\t\tAverage training MSE: 0.25069321323268706\n",
      "\t\tAverage testing MSE: 0.2508751987428388\n",
      "\tDegree 3:\n",
      "\t\tAverage training MSE: 0.25059882093423197\n",
      "\t\tAverage testing MSE: 0.2510078795169487\n",
      "\tDegree 4:\n",
      "\t\tAverage training MSE: 0.2503752794446565\n",
      "\t\tAverage testing MSE: 0.2512323133641475\n",
      "\tDegree 5:\n",
      "\t\tAverage training MSE: 0.24992789655633088\n",
      "\t\tAverage testing MSE: 0.2515857471823738\n",
      "\tPolynomial of degree 2 gives smallest test error\n",
      "\n",
      "Dataset 4\n",
      "\tDegree 2:\n",
      "\t\tAverage training MSE: 0.0038868411199233567\n",
      "\t\tAverage testing MSE: 0.0038881636008681214\n",
      "\tDegree 3:\n",
      "\t\tAverage training MSE: 0.0038857225542536316\n",
      "\t\tAverage testing MSE: 0.0038891921156731283\n",
      "\tDegree 4:\n",
      "\t\tAverage training MSE: 0.003459077176013503\n",
      "\t\tAverage testing MSE: 0.0034680915614961052\n",
      "\tDegree 5:\n",
      "\t\tAverage training MSE: 0.0034540512029444604\n",
      "\t\tAverage testing MSE: 0.0034733771681321516\n",
      "\tPolynomial of degree 4 gives smallest test error\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Map features to higher dimensional space using combinations of features and different degrees\n",
    "# Perform linear regression on the mapping and KFold cross validation to choose that right mapping for each dataset\n",
    "kf = KFold(n_splits=5)\n",
    "degrees = [2,3,4,5]\n",
    "best_models = []\n",
    "print(\"Performing 5-fold cross validation across 4 different polynomial mappings:\")\n",
    "for i, data in enumerate(sets):\n",
    "    # Take all columns except the last one\n",
    "    X = data.iloc[:,:-1].values\n",
    "    y = data.y.values\n",
    "    average_test_errors = []\n",
    "    average_train_errors = []\n",
    "    for degree in degrees:\n",
    "        train_errors = []\n",
    "        test_errors = []\n",
    "        # Start KFold for current degree of polynomial\n",
    "        for train_index, test_index in kf.split(X):\n",
    "            # Split to train and test for this fold\n",
    "            X_train, X_test = X[train_index], X[test_index]\n",
    "            y_train, y_test = y[train_index], y[test_index]\n",
    "            \n",
    "            # Create polynomial features\n",
    "            poly_reg = PolynomialFeatures(degree=degree)\n",
    "            X_train_poly = poly_reg.fit_transform(X_train)\n",
    "            X_test_poly = poly_reg.fit_transform(X_test)\n",
    "            \n",
    "            # Train LR\n",
    "            lr = LinearRegressionExplicit()\n",
    "            lr.fit(X_train_poly,y_train)\n",
    "            \n",
    "            # Predict and error\n",
    "            train_pred = lr.predict(X_train_poly)\n",
    "            test_pred = lr.predict(X_test_poly)\n",
    "            \n",
    "            # Save the MSE of this fold\n",
    "            train_errors.append(regression_error(train_pred,y_train))\n",
    "            test_errors.append(regression_error(test_pred,y_test))\n",
    "        \n",
    "        # Average the MSE across 5 fold for each mapping\n",
    "        average_test_errors.append(np.average(test_errors))\n",
    "        average_train_errors.append(np.average(train_errors))\n",
    "        \n",
    "    print(f\"Dataset {i+1}\")\n",
    "    for i, (average_train_error, average_test_error) in enumerate(zip(average_train_errors,average_test_errors)):\n",
    "        print(f\"\\tDegree {degrees[i]}:\")\n",
    "        print(f\"\\t\\tAverage training MSE: {average_train_error}\")\n",
    "        print(f\"\\t\\tAverage testing MSE: {average_test_error}\")\n",
    "    \n",
    "    print(f\"\\tPolynomial of degree {degrees[np.argmin(average_test_errors)]} gives smallest test error\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset 1:\n",
      "\tIterative:\n",
      "\t\tAverage train MSE: 0.2903976393701412\n",
      "\t\tAverage test MSE: 0.292034172422746\n",
      "\tExplicit:\n",
      "\t\tAverage train MSE: 0.25893288314771007\n",
      "\t\tAverage test MSE: 0.25893288314771007\n",
      "Dataset 2:\n",
      "\tIterative:\n",
      "\t\tAverage train MSE: 0.01991017797793271\n",
      "\t\tAverage test MSE: 0.019979081072201088\n",
      "\tExplicit:\n",
      "\t\tAverage train MSE: 0.019943633719617975\n",
      "\t\tAverage test MSE: 0.019943633719617975\n",
      "Dataset 3:\n",
      "\tIterative:\n",
      "\t\tAverage train MSE: 0.9897733390127728\n",
      "\t\tAverage test MSE: 0.9904899848411304\n",
      "\tExplicit:\n",
      "\t\tAverage train MSE: 0.25078420598776296\n",
      "\t\tAverage test MSE: 0.25078420598776296\n",
      "Dataset 4:\n",
      "\tIterative:\n",
      "\t\tAverage train MSE: 0.004144630842162844\n",
      "\t\tAverage test MSE: 0.004145749526527948\n",
      "\tExplicit:\n",
      "\t\tAverage train MSE: 0.0038875023603957394\n",
      "\t\tAverage test MSE: 0.0038875023603957394\n"
     ]
    }
   ],
   "source": [
    "# Choosing mapping of degree 2, solve the regression problem using explicit solution vs iterative\n",
    "\n",
    "for i, data in enumerate(sets):\n",
    "    # Take all columns except the last one\n",
    "    X = data.iloc[:,:-1].values\n",
    "    y = data.y.values\n",
    "    train_errors_explicit = []\n",
    "    test_errors_explicit = []\n",
    "    train_errors_iterative = []\n",
    "    test_errors_iterative = []\n",
    "    \n",
    "    # Start KFold\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "        # Create polynomial features\n",
    "        poly_reg = PolynomialFeatures(degree=2)\n",
    "        X_train_poly = poly_reg.fit_transform(X_train)\n",
    "        X_test_poly = poly_reg.fit_transform(X_test)\n",
    "\n",
    "        # LR explicit\n",
    "        # Train\n",
    "        lr_explicit = LinearRegressionExplicit()\n",
    "        lr_explicit.fit(X_train_poly,y_train)\n",
    "        \n",
    "        # Predict\n",
    "        train_pred = lr_explicit.predict(X_train_poly)\n",
    "        test_pred = lr_explicit.predict(X_test_poly)\n",
    "        \n",
    "        # MSE of fold\n",
    "        train_errors_explicit.append(regression_error(train_pred,y_train))\n",
    "        train_errors_explicit.append(regression_error(test_pred,y_test))\n",
    "        \n",
    "        # LR iterative\n",
    "        # Train\n",
    "        if i <= 1:\n",
    "            learning_rate = 1e-4\n",
    "        else:\n",
    "            learning_rate = 1e-6\n",
    "        lr_iterative = LinearRegressionIterative()\n",
    "        lr_iterative.fit(X_train_poly,y_train,10,learning_rate=learning_rate,verbose=0)\n",
    "        \n",
    "        # Predict\n",
    "        train_pred = lr_iterative.predict(X_train_poly)\n",
    "        test_pred = lr_iterative.predict(X_test_poly)\n",
    "        \n",
    "        # MSE of fold\n",
    "        train_errors_iterative.append(regression_error(train_pred,y_train))\n",
    "        test_errors_iterative.append(regression_error(test_pred,y_test))\n",
    "    \n",
    "    print(f\"Dataset {i+1}:\")\n",
    "    print(f\"\\tIterative:\")\n",
    "    print(f\"\\t\\tAverage train MSE: {np.average(train_errors_iterative)}\")\n",
    "    print(f\"\\t\\tAverage test MSE: {np.average(test_errors_iterative)}\")\n",
    "    print(f\"\\tExplicit:\")\n",
    "    print(f\"\\t\\tAverage train MSE: {np.average(train_errors_explicit)}\")\n",
    "    print(f\"\\t\\tAverage test MSE: {np.average(train_errors_explicit)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
